{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Regression: This model involves one independent variable and one dependent variable. It aims to model the relationship between them using a straight line. For example, predicting house price based on the size of the house.\n",
    "\n",
    "# Multiple Linear Regression: This model involves more than one independent variable and one dependent variable. It models the relationship between multiple predictors and a response. For example, predicting house price based on size, number of bedrooms, and location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linearity: The relationship between the independent and dependent variables must be linear.\n",
    "# Independence: Observations should be independent of each other.\n",
    "# Homoscedasticity: The variance of residuals should be constant across all levels of the independent variables.\n",
    "# Normality of Residuals: The residuals should be normally distributed.\n",
    "# No Multicollinearity: Independent variables should not be highly correlated.\n",
    "# You can check these assumptions using:\n",
    "\n",
    "# Linearity: Scatter plots and residual plots.\n",
    "# Independence: Durbin-Watson test.\n",
    "# Homoscedasticity: Plot residuals vs. fitted values.\n",
    "# Normality: Q-Q plot.\n",
    "# Multicollinearity: Variance Inflation Factor (VIF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope: Indicates how much the dependent variable changes with a one-unit increase in the independent variable.\n",
    "# Intercept: The expected value of the dependent variable when the independent variable is zero.\n",
    "# Example: In a linear model predicting salary based on years of experience, the slope would represent how much salary increases with each additional year of experience, and the intercept would indicate the salary with 0 years of experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models. It iteratively adjusts model parameters (weights) in the direction that reduces the error (the negative gradient) until it converges on the minimum error. It is widely used in training regression models, neural networks, and many other machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression models the relationship between one dependent variable and two or more independent variables. The model has the form:\n",
    "\n",
    "\n",
    "# Whereas simple linear regression only considers one independent variable. In multiple linear regression, interactions among independent variables are also modeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity occurs when two or more independent variables in a regression model are highly correlated, making it difficult to assess their individual effects on the dependent variable.\n",
    "\n",
    "# To detect multicollinearity:\n",
    "\n",
    "# Variance Inflation Factor (VIF): A VIF > 10 is often a sign of multicollinearity.\n",
    "# Correlation matrix: To see how variables correlate with each other.\n",
    "# To address multicollinearity:\n",
    "\n",
    "# Remove highly correlated predictors.\n",
    "# Combine correlated variables.\n",
    "# Use regularization techniques like Ridge Regression or Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Regression is an extension of linear regression where the relationship between the independent and dependent variable is modeled as an \n",
    "# ùëõ\n",
    "# ùë°\n",
    "# ‚Ñé\n",
    "# n \n",
    "# th\n",
    "#   degree polynomial. Unlike linear regression, which fits a straight line, polynomial regression fits a curve to the data.\n",
    "\n",
    "# For example, if the relationship between experience and salary is quadratic, a second-degree polynomial regression model might better capture the trend than a simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advantages:\n",
    "\n",
    "# Can model complex relationships between the variables.\n",
    "# Provides a better fit for non-linear data.\n",
    "# Disadvantages:\n",
    "\n",
    "# Prone to overfitting, especially with higher-degree polynomials.\n",
    "# Can become computationally expensive.\n",
    "# When to Use Polynomial Regression:\n",
    "\n",
    "# When the relationship between the independent and dependent variables is non-linear, and a simple linear model doesn't fit the data well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
