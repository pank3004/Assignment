{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Filter method selects features based on their statistical properties, independent of any machine learning algorithm. It evaluates the relevance of each feature using certain metrics and selects those that meet a predefined criterion.\n",
    "\n",
    "# How it works:\n",
    "\n",
    "# Statistical Tests: Use tests like chi-squared, correlation coefficients, or ANOVA to assess the relationship between each feature and the target variable.\n",
    "# Ranking: Features are ranked based on their scores from these tests.\n",
    "# Selection: A subset of features is chosen based on a threshold (e.g., top N features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Wrapper method evaluates subsets of features by actually training a model and assessing its performance. It uses a specific machine learning algorithm to determine the effectiveness of different combinations of features.\n",
    "\n",
    "# Key differences:\n",
    "\n",
    "# Evaluation: Filter methods assess features individually, while Wrapper methods evaluate combinations of features.\n",
    "# Performance Dependency: Wrapper methods can provide better performance as they are tailored to the model being used, whereas Filter methods are model-agnostic.\n",
    "# Computational Cost: Wrapper methods can be computationally expensive due to the need to train multiple models, especially with large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. What are some common techniques used in Embedded feature selection methods?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedded methods perform feature selection as part of the model training process. Some common techniques include:\n",
    "\n",
    "# Lasso Regression (L1 regularization): Encourages sparsity in feature selection by penalizing the absolute size of coefficients.\n",
    "# Ridge Regression (L2 regularization): Penalizes the size of coefficients, though it doesn’t necessarily eliminate features.\n",
    "# Decision Trees: Feature importance can be derived from tree-based algorithms like Random Forests, which consider the contribution of each feature to the prediction.\n",
    "# Regularized models: Models that incorporate feature selection directly into their training, such as Elastic Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. What are some drawbacks of using the Filter method for feature selection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Independence: Since it does not consider the model, the selected features may not be optimal for a specific learning algorithm.\n",
    "# Ignoring Interactions: Filter methods often overlook interactions between features since they assess features individually.\n",
    "# Arbitrary Thresholds: The choice of thresholds for feature selection can be subjective and affect the outcome.\n",
    "# Limited Insight: Does not provide insights into how features interact with the target variable within the context of a specific model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
    "selection?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High Dimensionality: When dealing with datasets with a large number of features (e.g., genomic data), the Filter method is faster and less computationally intensive.\n",
    "# Quick Insights: When you need a quick analysis of feature importance without training models.\n",
    "# Limited Computational Resources: When computational resources are limited, and the costs of multiple model evaluations in the Wrapper method are prohibitive.\n",
    "# Model Agnostic Needs: When the selected features need to be robust across multiple types of models rather than optimized for a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
    "You are unsure of which features to include in the model because the dataset contains several different\n",
    "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Data: Gather the dataset with customer features (e.g., usage patterns, payment history, customer service interactions).\n",
    "# Select Metrics: Choose appropriate statistical tests (e.g., chi-squared for categorical features, correlation for continuous features) to assess the relationship with the churn label.\n",
    "# Calculate Scores: Compute scores for each feature based on the chosen metrics to evaluate their relevance to customer churn.\n",
    "# Rank Features: Rank the features based on their scores.\n",
    "# Set a Threshold: Define a threshold (e.g., top 10 features) to select the most relevant attributes for further modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
    "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
    "method to select the most relevant features for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a Model: Select a machine learning model that incorporates embedded feature selection, such as a decision tree, random forest, or logistic regression with regularization.\n",
    "# Train the Model: Fit the model to the dataset, which includes various features like player statistics and team rankings.\n",
    "# Feature Importance: After training, extract feature importance scores that the model provides, reflecting how each feature contributes to the predictions.\n",
    "# Select Features: Choose the most important features based on their scores (e.g., selecting features with scores above a certain threshold).\n",
    "# Iterate: Optionally, retrain the model with the selected features to ensure the performance improves or remains stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
    "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
    "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
    "predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model: Choose a predictive model (e.g., linear regression, decision tree).\n",
    "# Initial Feature Set: Start with all available features in the dataset.\n",
    "# Subset Selection: Use techniques like forward selection, backward elimination, or recursive feature elimination:\n",
    "# Forward Selection: Start with no features and iteratively add features based on model performance improvement.\n",
    "# Backward Elimination: Start with all features and iteratively remove the least significant ones.\n",
    "# Recursive Feature Elimination (RFE): Train the model and remove features based on their importance recursively until reaching the desired number of features.\n",
    "# Model Evaluation: For each subset of features, evaluate model performance using cross-validation.\n",
    "# Select the Best Subset: Choose the subset of features that yields the best performance based on a predefined metric (e.g., RMSE, R²)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
